{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BOW AND TF-IDF IMPLEMENTATION\n"
      ],
      "metadata": {
        "id": "UoCj8qcjh3F_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MVWxTTf7hqdf"
      },
      "outputs": [],
      "source": [
        "#how to find unique words in your corpus\n",
        "# vocab\n",
        "corpus = ['this is the first sentence in out corpus followed by one more sentence to demonstrate bag of words',\n",
        "          'This is the second sentence in out corpus with a FEW UPPPEr and Few Tiltle Case Words']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = []\n",
        "total_words = 0\n",
        "for sentences in corpus:\n",
        "  sentences = sentences.lower()\n",
        "  token_temp = sentences.split()\n",
        "  total_words = total_words + len(token_temp)\n",
        "  for i in range(len(token_temp)):\n",
        "      if token_temp[i] not in vocab:\n",
        "        vocab.append(token_temp[i])"
      ],
      "metadata": {
        "id": "zZNCwHItjB0Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.sort()\n",
        "print(vocab,total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG6hKf4tjk_N",
        "outputId": "1fc88c9e-e036-486a-adca-34472e2933bd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'and', 'bag', 'by', 'case', 'corpus', 'demonstrate', 'few', 'first', 'followed', 'in', 'is', 'more', 'of', 'one', 'out', 'second', 'sentence', 'the', 'this', 'tiltle', 'to', 'uppper', 'with', 'words'] 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF\n"
      ],
      "metadata": {
        "id": "bh6snwlSsrd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "YVEP0dhgjpLo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\"I love Natural Language Processing\",\n",
        "        \"Creating word vectors\",\n",
        "        \"Is my jam!\"]"
      ],
      "metadata": {
        "id": "P4-pn2lQs1Vq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfvectorizer = TfidfVectorizer()\n",
        "vectorized_data = tfvectorizer.fit_transform(data)"
      ],
      "metadata": {
        "id": "eaatt9yztOu5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = vectorized_data.toarray()\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H7TYhjwtYHm",
        "outputId": "a79e7048-13a9-48ce-c942-6f5f08481252"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.5       , 0.5       ,\n",
              "        0.        , 0.5       , 0.5       , 0.        , 0.        ],\n",
              "       [0.57735027, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.57735027, 0.57735027],\n",
              "       [0.        , 0.57735027, 0.57735027, 0.        , 0.        ,\n",
              "        0.57735027, 0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "x_bow = cv.fit_transform(data).toarray()\n",
        "x_bow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luulgzzEtfKf",
        "outputId": "787c5389-e9e5-4029-d974-dfe36884e3a4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 1, 1, 0, 1, 1, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
              "       [0, 1, 1, 0, 0, 1, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GfIDF_gDt6B6"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}